{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ee0fcb-4c19-4f91-ae59-cbbe4ad7b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739db30d-759d-415f-a4c3-bc1e837f891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\"\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83578c83-31dd-48d1-93f2-1dad25e1a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 5))\n",
    "# True weights for our data, random normal variables again\n",
    "weights = torch.randn_like(features)\n",
    "# and a true bias term\n",
    "bias = torch.randn((1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4d524-085b-4d86-af68-6b18accdf51c",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the output of the network with input features features, weights weights, and bias bias. Similar to Numpy, PyTorch has a torch.sum() function, as well as a .sum() method on tensors, for taking sums. Use the function activation defined above as the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cc4d55-a034-4337-b5ee-7b569d5c59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(torch.sum(features*weights)+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdeffc3-9b44-491a-a351-fd1f695df068",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = weights.view(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38b5050-8b79-4ef2-be3b-8e4e5e272056",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner  = torch.mm(features, weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e622f3-04c0-465e-9dba-deec5e82984d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(inner+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dce9000-7320-47c1-a0e3-349091c9b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units \n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d60276-2f63-4748-906b-a602b2c55f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1468,  0.7861,  0.9468]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e26a6ce-5928-489e-8cdf-f5f317b98f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]),\n",
       " torch.Size([3, 2]),\n",
       " torch.Size([1, 2]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, W1.shape, B1.shape, W2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0e625-674f-4304-91ee-9114d398a536",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the output of our little network using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420a415a-60cb-4941-af10-2923d119b29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(torch.mm(activation(torch.mm(features, W1)+B1), W2)+B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91560016-26f7-4694-93f1-4fc14d6598b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9685, 0.3862, 0.5896],\n",
       "        [0.7640, 0.4622, 0.0480],\n",
       "        [0.7758, 0.6898, 0.6125],\n",
       "        [0.9667, 0.8099, 0.7890]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numpy to Torch and back\n",
    "\n",
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "b\n",
    "#The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221e59dc-5ef0-4a4c-a298-ed6f2ecd6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0bc513-fe7c-4d6e-848d-3eed1ad47c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb86f049-fda2-468c-978f-293b03ec666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cbd37e4-f94e-46b3-b5bd-e8a9ed109a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784  # Number of input units, must match number of input features\n",
    "n_hidden = 256                    # Number of hidden units \n",
    "n_output = 10\n",
    "\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1382a34-5fac-460b-b51d-64f5e3550de7",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the output for this multi-layer network using the weights W1 & W2, and the biases, B1 & B2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec60ea09-ec7d-4624-8967-63b367d5b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = images.reshape(64,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138af0f3-372b-47c9-b244-8dcd7e8826fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = activation(torch.mm(inputs, W1)+B1)\n",
    "out = (torch.mm(h, W2)+B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e5531-7a9c-49cf-9196-9d03761d5a2d",
   "metadata": {},
   "source": [
    "#### Exercise: Implement a function softmax that performs the softmax calculation and returns probability distributions for each example in the batch. Note that you'll need to pay attention to the shapes when doing this. If you have a tensor a with shape (64, 10) and a tensor b with shape (64,), doing a/b will give you an error because PyTorch will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. The way to think about this is for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need b to have a shape of (64, 1). This way PyTorch will divide the 10 values in each row of a by the one value in each row of b. Pay attention to how you take the sum as well. You'll need to define the dim keyword in torch.sum. Setting dim=0 takes the sum across the rows while dim=1 takes the sum across the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33887e72-87a7-412f-96ea-31aa84f6f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    proba = torch.exp(x)/torch.sum(torch.exp(x), dim=1).reshape(-1,1)\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "160eafff-0853-496b-9cae-2962ca23bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_batch = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afcb289d-ce28-4754-bef6-c7ec0a38343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b5d0f-9860-40d3-aa6c-41140bc876f3",
   "metadata": {},
   "source": [
    "### Exercise: Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the nn.ReLU module or F.relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf46db1e-2501-427e-ae79-5b1ca0e9561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a NN\n",
    "\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        F.relu_(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        F.relu_(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a733ef-f529-46d1-ab72-34f1e4746bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17fe6d3e-5bf3-4039-8fdc-4ce5d43241be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0020,  0.0088, -0.0289,  0.0308,  0.0061, -0.0162,  0.0313,  0.0208,\n",
       "         0.0323, -0.0276, -0.0059, -0.0044,  0.0304, -0.0246,  0.0104,  0.0065,\n",
       "         0.0301,  0.0106, -0.0293, -0.0130, -0.0125,  0.0344,  0.0063,  0.0027,\n",
       "        -0.0290, -0.0088,  0.0100,  0.0220,  0.0140, -0.0021, -0.0099, -0.0019,\n",
       "        -0.0085,  0.0056,  0.0130, -0.0014, -0.0033,  0.0240,  0.0133, -0.0035,\n",
       "         0.0331,  0.0079, -0.0302,  0.0092,  0.0003, -0.0261,  0.0026,  0.0224,\n",
       "         0.0279,  0.0009, -0.0170, -0.0029,  0.0061,  0.0346, -0.0096,  0.0117,\n",
       "        -0.0053, -0.0162,  0.0148,  0.0297, -0.0034, -0.0155, -0.0254,  0.0152,\n",
       "        -0.0189,  0.0064,  0.0296, -0.0209,  0.0226, -0.0183,  0.0039,  0.0233,\n",
       "         0.0065, -0.0059, -0.0104,  0.0311, -0.0313,  0.0212, -0.0066,  0.0267,\n",
       "         0.0344, -0.0159,  0.0112,  0.0274,  0.0094, -0.0046,  0.0184,  0.0238,\n",
       "         0.0060, -0.0144,  0.0214,  0.0037, -0.0174,  0.0211,  0.0266, -0.0325,\n",
       "        -0.0193,  0.0121, -0.0264, -0.0155,  0.0146,  0.0291, -0.0260, -0.0098,\n",
       "         0.0079, -0.0162, -0.0270,  0.0297, -0.0053, -0.0333, -0.0107,  0.0172,\n",
       "        -0.0041,  0.0311, -0.0103,  0.0053, -0.0060, -0.0217,  0.0307, -0.0301,\n",
       "        -0.0278,  0.0104, -0.0310,  0.0207,  0.0152,  0.0336,  0.0176,  0.0106],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4af9b36d-42eb-45d9-8942-267c8547e93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "928f7c2d-b87f-4f15-947a-35fee7a79f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0015, -0.0082,  0.0019,  ..., -0.0056,  0.0065,  0.0006],\n",
       "        [-0.0025, -0.0009,  0.0168,  ...,  0.0090,  0.0057,  0.0020],\n",
       "        [-0.0038, -0.0063,  0.0171,  ..., -0.0149,  0.0168,  0.0037],\n",
       "        ...,\n",
       "        [ 0.0060, -0.0162,  0.0037,  ..., -0.0004, -0.0097, -0.0087],\n",
       "        [ 0.0021, -0.0020, -0.0031,  ..., -0.0080,  0.0098, -0.0050],\n",
       "        [ 0.0138, -0.0074,  0.0163,  ...,  0.0021, -0.0081, -0.0025]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5e5e723-35be-4609-95c5-02e728d30f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7581efbf-c0b1-48f1-8bbe-2561180f226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a0086ca-83f3-4cb8-add3-5fbe40a6021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46347110-994b-4ed1-8d45-b00cba9e3b42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9373, -0.7020,\n",
       "         -0.7020, -0.7020, -0.3882,  0.1451,  0.1451,  0.1451,  0.6000,  1.0000,\n",
       "         -0.0510, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7098,  0.4431,\n",
       "          0.4431,  0.4431,  0.5451,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "          0.9843,  0.9843,  0.9843,  0.9843,  0.9843, -0.9608, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000,  0.6314,  0.9843,  0.9843,  0.9843,  0.9451,  0.9765,\n",
       "          0.9843,  0.9843,  0.9843,  0.9451,  0.7412,  0.0902,  0.9373,  0.9843,\n",
       "          0.9843, -0.6000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5922,  0.7804,\n",
       "          0.0118, -0.2314, -1.0000, -0.3804, -0.2000, -0.2000, -0.2000, -0.9451,\n",
       "         -1.0000, -0.8667,  0.5843,  0.9843,  0.5059, -0.9843, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.7725, -0.7961, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0353,  0.9843,  0.9843,\n",
       "         -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.5373,  0.9529,  0.9843,  0.7490, -0.8196, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000,  0.3176,  0.9843,  0.9451, -0.1608,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8667,\n",
       "          0.8353,  0.9843,  0.4824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000,  0.0039,  0.9843,  0.9373, -0.4902, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8667,\n",
       "          0.9843,  0.2235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.1137,  0.9608,  0.9843, -0.0824, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5922,  0.9608,  0.9843,\n",
       "          0.1137, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.9686,  0.1529,  0.9843,  0.6784, -0.7725, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -0.1765,  0.9843,  0.9843, -0.3569,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          0.7961,  0.9843,  0.6784, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -0.5294,  0.9373,  0.9843,  0.2784, -0.9608,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3176,\n",
       "          0.9843,  0.9843, -0.5765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -0.3176,  0.9843,  0.9843, -0.5765, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5059,\n",
       "          0.9451,  0.9843,  0.5216, -0.6784, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -0.3098,  0.6784,  0.9843, -0.3882,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb9c3c52-1f8c-4500-9b8f-4f20265f52ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Build a feed-forward network\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      3\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m      4\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m      5\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m      6\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m----> 7\u001b[0m                       \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define the loss\u001b[39;00m\n\u001b[1;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[0;32m~/anaconda3/envs/co2/lib/python3.9/site-packages/torch/nn/functional.py:1905\u001b[0m, in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(log_softmax, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, dim\u001b[38;5;241m=\u001b[39mdim, _stacklevel\u001b[38;5;241m=\u001b[39m_stacklevel, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1905\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m(), _stacklevel)\n\u001b[1;32m   1906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1907\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mlog_softmax(dim)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      F.log_softmax(10,))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bc065-7587-4e58-9b41-f3efaf931a63",
   "metadata": {},
   "source": [
    "## Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d001b5e-f532-4361-bd43-b779f9686451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "672e460a-04f6-499c-a62d-0c6e7899978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d33ae-b90f-44da-814d-bdf0bd2af86e",
   "metadata": {},
   "source": [
    "## Exercise: Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2b03f21-84e5-4820-a68c-b51e49a82f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f728478aba0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21dbca6a-04e2-4984-be62-25b8c578b6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9546953221119798\n",
      "Training loss: 0.8970477165761532\n",
      "Training loss: 0.5417207487102257\n",
      "Training loss: 0.44127489353166716\n",
      "Training loss: 0.39231130943846093\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        output = model(images)        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9994afa8-5a81-471c-a390-d7e2c2c19c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[25].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dc699-5998-4b82-8adf-50f8f6af983f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
