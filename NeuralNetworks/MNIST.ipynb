{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ee0fcb-4c19-4f91-ae59-cbbe4ad7b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739db30d-759d-415f-a4c3-bc1e837f891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\"\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83578c83-31dd-48d1-93f2-1dad25e1a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 5))\n",
    "# True weights for our data, random normal variables again\n",
    "weights = torch.randn_like(features)\n",
    "# and a true bias term\n",
    "bias = torch.randn((1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4d524-085b-4d86-af68-6b18accdf51c",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the output of the network with input features features, weights weights, and bias bias. Similar to Numpy, PyTorch has a torch.sum() function, as well as a .sum() method on tensors, for taking sums. Use the function activation defined above as the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cc4d55-a034-4337-b5ee-7b569d5c59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(torch.sum(features*weights)+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdeffc3-9b44-491a-a351-fd1f695df068",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = weights.view(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38b5050-8b79-4ef2-be3b-8e4e5e272056",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner  = torch.mm(features, weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e622f3-04c0-465e-9dba-deec5e82984d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(inner+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dce9000-7320-47c1-a0e3-349091c9b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units \n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d60276-2f63-4748-906b-a602b2c55f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1468,  0.7861,  0.9468]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e26a6ce-5928-489e-8cdf-f5f317b98f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]),\n",
       " torch.Size([3, 2]),\n",
       " torch.Size([1, 2]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, W1.shape, B1.shape, W2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0e625-674f-4304-91ee-9114d398a536",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the output of our little network using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420a415a-60cb-4941-af10-2923d119b29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(torch.mm(activation(torch.mm(features, W1)+B1), W2)+B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91560016-26f7-4694-93f1-4fc14d6598b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9685, 0.3862, 0.5896],\n",
       "        [0.7640, 0.4622, 0.0480],\n",
       "        [0.7758, 0.6898, 0.6125],\n",
       "        [0.9667, 0.8099, 0.7890]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numpy to Torch and back\n",
    "\n",
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "b\n",
    "#The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221e59dc-5ef0-4a4c-a298-ed6f2ecd6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0bc513-fe7c-4d6e-848d-3eed1ad47c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb86f049-fda2-468c-978f-293b03ec666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cbd37e4-f94e-46b3-b5bd-e8a9ed109a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784  # Number of input units, must match number of input features\n",
    "n_hidden = 256                    # Number of hidden units \n",
    "n_output = 10\n",
    "\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1382a34-5fac-460b-b51d-64f5e3550de7",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the output for this multi-layer network using the weights W1 & W2, and the biases, B1 & B2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec60ea09-ec7d-4624-8967-63b367d5b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = images.reshape(64,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138af0f3-372b-47c9-b244-8dcd7e8826fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = activation(torch.mm(inputs, W1)+B1)\n",
    "out = (torch.mm(h, W2)+B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e5531-7a9c-49cf-9196-9d03761d5a2d",
   "metadata": {},
   "source": [
    "#### Exercise: Implement a function softmax that performs the softmax calculation and returns probability distributions for each example in the batch. Note that you'll need to pay attention to the shapes when doing this. If you have a tensor a with shape (64, 10) and a tensor b with shape (64,), doing a/b will give you an error because PyTorch will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. The way to think about this is for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need b to have a shape of (64, 1). This way PyTorch will divide the 10 values in each row of a by the one value in each row of b. Pay attention to how you take the sum as well. You'll need to define the dim keyword in torch.sum. Setting dim=0 takes the sum across the rows while dim=1 takes the sum across the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33887e72-87a7-412f-96ea-31aa84f6f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    proba = torch.exp(x)/torch.sum(torch.exp(x), dim=1).reshape(-1,1)\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "160eafff-0853-496b-9cae-2962ca23bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_batch = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afcb289d-ce28-4754-bef6-c7ec0a38343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b5d0f-9860-40d3-aa6c-41140bc876f3",
   "metadata": {},
   "source": [
    "### Exercise: Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the nn.ReLU module or F.relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf46db1e-2501-427e-ae79-5b1ca0e9561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a NN\n",
    "\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        F.relu_(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        F.relu_(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a733ef-f529-46d1-ab72-34f1e4746bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17fe6d3e-5bf3-4039-8fdc-4ce5d43241be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0020,  0.0088, -0.0289,  0.0308,  0.0061, -0.0162,  0.0313,  0.0208,\n",
       "         0.0323, -0.0276, -0.0059, -0.0044,  0.0304, -0.0246,  0.0104,  0.0065,\n",
       "         0.0301,  0.0106, -0.0293, -0.0130, -0.0125,  0.0344,  0.0063,  0.0027,\n",
       "        -0.0290, -0.0088,  0.0100,  0.0220,  0.0140, -0.0021, -0.0099, -0.0019,\n",
       "        -0.0085,  0.0056,  0.0130, -0.0014, -0.0033,  0.0240,  0.0133, -0.0035,\n",
       "         0.0331,  0.0079, -0.0302,  0.0092,  0.0003, -0.0261,  0.0026,  0.0224,\n",
       "         0.0279,  0.0009, -0.0170, -0.0029,  0.0061,  0.0346, -0.0096,  0.0117,\n",
       "        -0.0053, -0.0162,  0.0148,  0.0297, -0.0034, -0.0155, -0.0254,  0.0152,\n",
       "        -0.0189,  0.0064,  0.0296, -0.0209,  0.0226, -0.0183,  0.0039,  0.0233,\n",
       "         0.0065, -0.0059, -0.0104,  0.0311, -0.0313,  0.0212, -0.0066,  0.0267,\n",
       "         0.0344, -0.0159,  0.0112,  0.0274,  0.0094, -0.0046,  0.0184,  0.0238,\n",
       "         0.0060, -0.0144,  0.0214,  0.0037, -0.0174,  0.0211,  0.0266, -0.0325,\n",
       "        -0.0193,  0.0121, -0.0264, -0.0155,  0.0146,  0.0291, -0.0260, -0.0098,\n",
       "         0.0079, -0.0162, -0.0270,  0.0297, -0.0053, -0.0333, -0.0107,  0.0172,\n",
       "        -0.0041,  0.0311, -0.0103,  0.0053, -0.0060, -0.0217,  0.0307, -0.0301,\n",
       "        -0.0278,  0.0104, -0.0310,  0.0207,  0.0152,  0.0336,  0.0176,  0.0106],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4af9b36d-42eb-45d9-8942-267c8547e93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "928f7c2d-b87f-4f15-947a-35fee7a79f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0015, -0.0082,  0.0019,  ..., -0.0056,  0.0065,  0.0006],\n",
       "        [-0.0025, -0.0009,  0.0168,  ...,  0.0090,  0.0057,  0.0020],\n",
       "        [-0.0038, -0.0063,  0.0171,  ..., -0.0149,  0.0168,  0.0037],\n",
       "        ...,\n",
       "        [ 0.0060, -0.0162,  0.0037,  ..., -0.0004, -0.0097, -0.0087],\n",
       "        [ 0.0021, -0.0020, -0.0031,  ..., -0.0080,  0.0098, -0.0050],\n",
       "        [ 0.0138, -0.0074,  0.0163,  ...,  0.0021, -0.0081, -0.0025]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5e5e723-35be-4609-95c5-02e728d30f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7581efbf-c0b1-48f1-8bbe-2561180f226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a0086ca-83f3-4cb8-add3-5fbe40a6021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46347110-994b-4ed1-8d45-b00cba9e3b42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9373, -0.7020,\n",
       "         -0.7020, -0.7020, -0.3882,  0.1451,  0.1451,  0.1451,  0.6000,  1.0000,\n",
       "         -0.0510, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7098,  0.4431,\n",
       "          0.4431,  0.4431,  0.5451,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "          0.9843,  0.9843,  0.9843,  0.9843,  0.9843, -0.9608, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000,  0.6314,  0.9843,  0.9843,  0.9843,  0.9451,  0.9765,\n",
       "          0.9843,  0.9843,  0.9843,  0.9451,  0.7412,  0.0902,  0.9373,  0.9843,\n",
       "          0.9843, -0.6000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5922,  0.7804,\n",
       "          0.0118, -0.2314, -1.0000, -0.3804, -0.2000, -0.2000, -0.2000, -0.9451,\n",
       "         -1.0000, -0.8667,  0.5843,  0.9843,  0.5059, -0.9843, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.7725, -0.7961, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0353,  0.9843,  0.9843,\n",
       "         -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.5373,  0.9529,  0.9843,  0.7490, -0.8196, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000,  0.3176,  0.9843,  0.9451, -0.1608,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8667,\n",
       "          0.8353,  0.9843,  0.4824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000,  0.0039,  0.9843,  0.9373, -0.4902, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8667,\n",
       "          0.9843,  0.2235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.1137,  0.9608,  0.9843, -0.0824, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5922,  0.9608,  0.9843,\n",
       "          0.1137, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.9686,  0.1529,  0.9843,  0.6784, -0.7725, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -0.1765,  0.9843,  0.9843, -0.3569,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          0.7961,  0.9843,  0.6784, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -0.5294,  0.9373,  0.9843,  0.2784, -0.9608,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3176,\n",
       "          0.9843,  0.9843, -0.5765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -0.3176,  0.9843,  0.9843, -0.5765, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5059,\n",
       "          0.9451,  0.9843,  0.5216, -0.6784, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -0.3098,  0.6784,  0.9843, -0.3882,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb9c3c52-1f8c-4500-9b8f-4f20265f52ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Build a feed-forward network\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      3\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m      4\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m      5\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m      6\u001b[0m                       nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m----> 7\u001b[0m                       \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define the loss\u001b[39;00m\n\u001b[1;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[0;32m~/anaconda3/envs/co2/lib/python3.9/site-packages/torch/nn/functional.py:1905\u001b[0m, in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(log_softmax, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, dim\u001b[38;5;241m=\u001b[39mdim, _stacklevel\u001b[38;5;241m=\u001b[39m_stacklevel, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1905\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m(), _stacklevel)\n\u001b[1;32m   1906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1907\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mlog_softmax(dim)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      F.log_softmax(10,))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bc065-7587-4e58-9b41-f3efaf931a63",
   "metadata": {},
   "source": [
    "## Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d001b5e-f532-4361-bd43-b779f9686451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "672e460a-04f6-499c-a62d-0c6e7899978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d33ae-b90f-44da-814d-bdf0bd2af86e",
   "metadata": {},
   "source": [
    "## Exercise: Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2b03f21-84e5-4820-a68c-b51e49a82f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f728478aba0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21dbca6a-04e2-4984-be62-25b8c578b6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9546953221119798\n",
      "Training loss: 0.8970477165761532\n",
      "Training loss: 0.5417207487102257\n",
      "Training loss: 0.44127489353166716\n",
      "Training loss: 0.39231130943846093\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        output = model(images)        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9994afa8-5a81-471c-a390-d7e2c2c19c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[12].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dc699-5998-4b82-8adf-50f8f6af983f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
